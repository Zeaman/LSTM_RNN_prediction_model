{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP-based Values prediction "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install required dependency libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInstall required dependency libraries\\n-pip install pandas\\n-pip install scikit-learn\\n-pip install tensorflow\\n-import matplotlib.pyplot as plt\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Install required dependency libraries\n",
    "-pip install pandas\n",
    "-pip install scikit-learn\n",
    "-pip install tensorflow\n",
    "-import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Import installed required dependency libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for LSTM model\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare the datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a pandas dataframe\n",
    "dataframe = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 248776 entries, 0 to 248775\n",
      "Data columns (total 94 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   index                      248776 non-null  int64  \n",
      " 1   open                       248776 non-null  float64\n",
      " 2   high                       248776 non-null  float64\n",
      " 3   close                      248776 non-null  float64\n",
      " 4   low                        248776 non-null  float64\n",
      " 5   timestamp                  248776 non-null  int64  \n",
      " 6   transactions               248776 non-null  int64  \n",
      " 7   volume                     248776 non-null  int64  \n",
      " 8   volume_adi                 248776 non-null  float64\n",
      " 9   volume_obv                 248776 non-null  int64  \n",
      " 10  volume_cmf                 248776 non-null  float64\n",
      " 11  volume_fi                  248776 non-null  float64\n",
      " 12  volume_em                  248776 non-null  float64\n",
      " 13  volume_sma_em              248776 non-null  float64\n",
      " 14  volume_vpt                 248776 non-null  float64\n",
      " 15  volume_vwap                248776 non-null  float64\n",
      " 16  volume_mfi                 248776 non-null  float64\n",
      " 17  volume_nvi                 248776 non-null  float64\n",
      " 18  volatility_bbm             248776 non-null  float64\n",
      " 19  volatility_bbh             248776 non-null  float64\n",
      " 20  volatility_bbl             248776 non-null  float64\n",
      " 21  volatility_bbw             248776 non-null  float64\n",
      " 22  volatility_bbp             248776 non-null  float64\n",
      " 23  volatility_bbhi            248776 non-null  float64\n",
      " 24  volatility_bbli            248776 non-null  float64\n",
      " 25  volatility_kcc             248776 non-null  float64\n",
      " 26  volatility_kch             248776 non-null  float64\n",
      " 27  volatility_kcl             248776 non-null  float64\n",
      " 28  volatility_kcw             248776 non-null  float64\n",
      " 29  volatility_kcp             248776 non-null  float64\n",
      " 30  volatility_kchi            248776 non-null  float64\n",
      " 31  volatility_kcli            248776 non-null  float64\n",
      " 32  volatility_dcl             248776 non-null  float64\n",
      " 33  volatility_dch             248776 non-null  float64\n",
      " 34  volatility_dcm             248776 non-null  float64\n",
      " 35  volatility_dcw             248776 non-null  float64\n",
      " 36  volatility_dcp             248776 non-null  float64\n",
      " 37  volatility_atr             248776 non-null  float64\n",
      " 38  volatility_ui              248776 non-null  float64\n",
      " 39  trend_macd                 248776 non-null  float64\n",
      " 40  trend_macd_signal          248776 non-null  float64\n",
      " 41  trend_macd_diff            248776 non-null  float64\n",
      " 42  trend_sma_fast             248776 non-null  float64\n",
      " 43  trend_sma_slow             248776 non-null  float64\n",
      " 44  trend_ema_fast             248776 non-null  float64\n",
      " 45  trend_ema_slow             248776 non-null  float64\n",
      " 46  trend_vortex_ind_pos       248776 non-null  float64\n",
      " 47  trend_vortex_ind_neg       248776 non-null  float64\n",
      " 48  trend_vortex_ind_diff      248776 non-null  float64\n",
      " 49  trend_trix                 248776 non-null  float64\n",
      " 50  trend_mass_index           248776 non-null  float64\n",
      " 51  trend_dpo                  248776 non-null  float64\n",
      " 52  trend_kst                  248776 non-null  float64\n",
      " 53  trend_kst_sig              248776 non-null  float64\n",
      " 54  trend_kst_diff             248776 non-null  float64\n",
      " 55  trend_ichimoku_conv        248776 non-null  float64\n",
      " 56  trend_ichimoku_base        248776 non-null  float64\n",
      " 57  trend_ichimoku_a           248776 non-null  float64\n",
      " 58  trend_ichimoku_b           248776 non-null  float64\n",
      " 59  trend_stc                  248776 non-null  float64\n",
      " 60  trend_adx                  248776 non-null  float64\n",
      " 61  trend_adx_pos              248776 non-null  float64\n",
      " 62  trend_adx_neg              248776 non-null  float64\n",
      " 63  trend_cci                  248776 non-null  float64\n",
      " 64  trend_visual_ichimoku_a    248776 non-null  float64\n",
      " 65  trend_visual_ichimoku_b    248776 non-null  float64\n",
      " 66  trend_aroon_up             248776 non-null  float64\n",
      " 67  trend_aroon_down           248776 non-null  float64\n",
      " 68  trend_aroon_ind            248776 non-null  float64\n",
      " 69  trend_psar_up              248776 non-null  float64\n",
      " 70  trend_psar_down            248776 non-null  float64\n",
      " 71  trend_psar_up_indicator    248776 non-null  float64\n",
      " 72  trend_psar_down_indicator  248776 non-null  float64\n",
      " 73  momentum_rsi               248776 non-null  float64\n",
      " 74  momentum_stoch_rsi         248776 non-null  float64\n",
      " 75  momentum_stoch_rsi_k       248776 non-null  float64\n",
      " 76  momentum_stoch_rsi_d       248776 non-null  float64\n",
      " 77  momentum_tsi               248776 non-null  float64\n",
      " 78  momentum_uo                248776 non-null  float64\n",
      " 79  momentum_stoch             248776 non-null  float64\n",
      " 80  momentum_stoch_signal      248776 non-null  float64\n",
      " 81  momentum_wr                248776 non-null  float64\n",
      " 82  momentum_ao                248776 non-null  float64\n",
      " 83  momentum_roc               248776 non-null  float64\n",
      " 84  momentum_ppo               248776 non-null  float64\n",
      " 85  momentum_ppo_signal        248776 non-null  float64\n",
      " 86  momentum_ppo_hist          248776 non-null  float64\n",
      " 87  momentum_pvo               248776 non-null  float64\n",
      " 88  momentum_pvo_signal        248776 non-null  float64\n",
      " 89  momentum_pvo_hist          248776 non-null  float64\n",
      " 90  momentum_kama              248776 non-null  float64\n",
      " 91  others_dr                  248776 non-null  float64\n",
      " 92  others_dlr                 248776 non-null  float64\n",
      " 93  others_cr                  248776 non-null  float64\n",
      "dtypes: float64(89), int64(5)\n",
      "memory usage: 178.4 MB\n"
     ]
    }
   ],
   "source": [
    "#To see the whole inforamtion contenet of the above dataset:\n",
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>transactions</th>\n",
       "      <th>volume</th>\n",
       "      <th>volume_adi</th>\n",
       "      <th>volume_obv</th>\n",
       "      <th>...</th>\n",
       "      <th>momentum_ppo</th>\n",
       "      <th>momentum_ppo_signal</th>\n",
       "      <th>momentum_ppo_hist</th>\n",
       "      <th>momentum_pvo</th>\n",
       "      <th>momentum_pvo_signal</th>\n",
       "      <th>momentum_pvo_hist</th>\n",
       "      <th>momentum_kama</th>\n",
       "      <th>others_dr</th>\n",
       "      <th>others_dlr</th>\n",
       "      <th>others_cr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.30785</td>\n",
       "      <td>1.30805</td>\n",
       "      <td>1.30802</td>\n",
       "      <td>1.30776</td>\n",
       "      <td>1367884800000</td>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>373.551724</td>\n",
       "      <td>471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.308020</td>\n",
       "      <td>12.794800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.30803</td>\n",
       "      <td>1.30840</td>\n",
       "      <td>1.30830</td>\n",
       "      <td>1.30785</td>\n",
       "      <td>1367885700000</td>\n",
       "      <td>561</td>\n",
       "      <td>561</td>\n",
       "      <td>730.551724</td>\n",
       "      <td>1032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>1.503033</td>\n",
       "      <td>0.300607</td>\n",
       "      <td>1.202426</td>\n",
       "      <td>1.308143</td>\n",
       "      <td>0.021406</td>\n",
       "      <td>0.021404</td>\n",
       "      <td>0.021406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.30830</td>\n",
       "      <td>1.30884</td>\n",
       "      <td>1.30781</td>\n",
       "      <td>1.30780</td>\n",
       "      <td>1367886600000</td>\n",
       "      <td>2309</td>\n",
       "      <td>2309</td>\n",
       "      <td>-1534.044430</td>\n",
       "      <td>-1277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>-0.000243</td>\n",
       "      <td>24.809883</td>\n",
       "      <td>5.202462</td>\n",
       "      <td>19.607421</td>\n",
       "      <td>1.307998</td>\n",
       "      <td>-0.037453</td>\n",
       "      <td>-0.037460</td>\n",
       "      <td>-0.016055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.30781</td>\n",
       "      <td>1.30836</td>\n",
       "      <td>1.30810</td>\n",
       "      <td>1.30771</td>\n",
       "      <td>1367887500000</td>\n",
       "      <td>1909</td>\n",
       "      <td>1909</td>\n",
       "      <td>-1152.244430</td>\n",
       "      <td>632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>32.724413</td>\n",
       "      <td>10.706852</td>\n",
       "      <td>22.017561</td>\n",
       "      <td>1.308042</td>\n",
       "      <td>0.022174</td>\n",
       "      <td>0.022172</td>\n",
       "      <td>0.006116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.30809</td>\n",
       "      <td>1.30833</td>\n",
       "      <td>1.30819</td>\n",
       "      <td>1.30791</td>\n",
       "      <td>1367888400000</td>\n",
       "      <td>926</td>\n",
       "      <td>926</td>\n",
       "      <td>-843.577763</td>\n",
       "      <td>1558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>29.460350</td>\n",
       "      <td>14.457552</td>\n",
       "      <td>15.002799</td>\n",
       "      <td>1.308107</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>0.006880</td>\n",
       "      <td>0.012997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index     open     high    close      low      timestamp  transactions   \n",
       "0      0  1.30785  1.30805  1.30802  1.30776  1367884800000           471  \\\n",
       "1      1  1.30803  1.30840  1.30830  1.30785  1367885700000           561   \n",
       "2      2  1.30830  1.30884  1.30781  1.30780  1367886600000          2309   \n",
       "3      3  1.30781  1.30836  1.30810  1.30771  1367887500000          1909   \n",
       "4      4  1.30809  1.30833  1.30819  1.30791  1367888400000           926   \n",
       "\n",
       "   volume   volume_adi  volume_obv  ...  momentum_ppo  momentum_ppo_signal   \n",
       "0     471   373.551724         471  ...      0.000000             0.000000  \\\n",
       "1     561   730.551724        1032  ...      0.001708             0.000342   \n",
       "2    2309 -1534.044430       -1277  ...      0.000038             0.000281   \n",
       "3    1909 -1152.244430         632  ...      0.000498             0.000324   \n",
       "4     926  -843.577763        1558  ...      0.001401             0.000539   \n",
       "\n",
       "   momentum_ppo_hist  momentum_pvo  momentum_pvo_signal  momentum_pvo_hist   \n",
       "0           0.000000      0.000000             0.000000           0.000000  \\\n",
       "1           0.001366      1.503033             0.300607           1.202426   \n",
       "2          -0.000243     24.809883             5.202462          19.607421   \n",
       "3           0.000173     32.724413            10.706852          22.017561   \n",
       "4           0.000862     29.460350            14.457552          15.002799   \n",
       "\n",
       "   momentum_kama  others_dr  others_dlr  others_cr  \n",
       "0       1.308020  12.794800    0.000000   0.000000  \n",
       "1       1.308143   0.021406    0.021404   0.021406  \n",
       "2       1.307998  -0.037453   -0.037460  -0.016055  \n",
       "3       1.308042   0.022174    0.022172   0.006116  \n",
       "4       1.308107   0.006880    0.006880   0.012997  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see the first five data content of the above dataset:\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows containing NaN values\n",
    "dataframe = dataframe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the time and target columns into separate variables\n",
    "time = dataframe.iloc[:, 0].values\n",
    "target = dataframe.iloc[:, 2:5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the time and target columns from the original dataframe to get the input data\n",
    "inputs =dataframe.iloc[:, 5:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with only the input data\n",
    "new_dataframe = pd.DataFrame(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0       1       2            3       4         5         6    \n",
      "0  1.367885e+12   471.0   471.0   373.551724   471.0  0.793103  0.000000  \\\n",
      "1  1.367886e+12   561.0   561.0   730.551724  1032.0  0.707899  0.157080   \n",
      "2  1.367887e+12  2309.0  2309.0 -1534.044430 -1277.0 -0.459157 -0.026990   \n",
      "3  1.367888e+12  1909.0  1909.0 -1152.244430   632.0 -0.219475  0.055953   \n",
      "4  1.367888e+12   926.0   926.0  -843.577763  1558.0 -0.136590  0.059865   \n",
      "\n",
      "         7         8          9   ...        79        80        81   \n",
      "0  0.000000  0.000000  60.271755  ...  0.000000  0.000000  0.000000  \\\n",
      "1  0.021569  0.021569  60.383598  ...  0.001708  0.000342  0.001366   \n",
      "2  0.008783  0.015176  -0.744704  ...  0.000038  0.000281 -0.000243   \n",
      "3 -0.009704  0.006883  -0.441483  ...  0.000498  0.000324  0.000173   \n",
      "4  0.003855  0.006126   0.487021  ...  0.001401  0.000539  0.000862   \n",
      "\n",
      "          82         83         84        85         86        87        88  \n",
      "0   0.000000   0.000000   0.000000  1.308020  12.794800  0.000000  0.000000  \n",
      "1   1.503033   0.300607   1.202426  1.308143   0.021406  0.021404  0.021406  \n",
      "2  24.809883   5.202462  19.607421  1.307998  -0.037453 -0.037460 -0.016055  \n",
      "3  32.724413  10.706852  22.017561  1.308042   0.022174  0.022172  0.006116  \n",
      "4  29.460350  14.457552  15.002799  1.308107   0.006880  0.006880  0.012997  \n",
      "\n",
      "[5 rows x 89 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the new dataframe\n",
    "print(new_dataframe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the input data and target values into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the input data using a scaler like the StandardScaler from sklearn.preprocessing\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the input data into a 3D tensor for use with the LSTM model\n",
    "X_train_reshaped = np.reshape(X_train_scaled, (X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_test_reshaped = np.reshape(X_test_scaled, (X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Define and build the LSTM-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Sequential model from Keras\n",
    "lstm_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an LSTM layer with 128 units and input shape of (1, 28)\n",
    "lstm_model.add(LSTM(units=128, input_shape=(1, 28)))\n",
    "# Add a fully connected dense layer with 64 units\n",
    "lstm_model.add(Dense(units=64, activation='relu'))\n",
    "# Add another dropout layer\n",
    "lstm_model.add(Dropout(0.2))\n",
    "# Add a fully connected dense layer with 32 units\n",
    "lstm_model.add(Dense(units=32, activation='relu'))\n",
    "# Add an output layer with 3 units (one for each target variable)\n",
    "lstm_model.add(Dense(units=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using the 'adam' optimizer and mean squared error loss function\n",
    "lstm_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train the LSTM-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"d:\\AI\\Value_prediction\\value_pred\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\AI\\Value_prediction\\value_pred\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\AI\\Value_prediction\\value_pred\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\AI\\Value_prediction\\value_pred\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\AI\\Value_prediction\\value_pred\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\AI\\Value_prediction\\value_pred\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 1, 28), found shape=(None, 1, 89)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train the model on the training dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m lstm_model\u001b[39m.\u001b[39;49mfit(X_train_reshaped, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test_reshaped, y_test), callbacks\u001b[39m=\u001b[39;49m[early_stopping])\n",
      "File \u001b[1;32md:\\AI\\Value_prediction\\value_pred\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file06m97k52.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"d:\\AI\\Value_prediction\\value_pred\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\AI\\Value_prediction\\value_pred\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\AI\\Value_prediction\\value_pred\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\AI\\Value_prediction\\value_pred\\lib\\site-packages\\keras\\engine\\training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"d:\\AI\\Value_prediction\\value_pred\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"d:\\AI\\Value_prediction\\value_pred\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 1, 28), found shape=(None, 1, 89)\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training dataset\n",
    "lstm_model.fit(X_train_reshaped, y_train, epochs=20, batch_size=32, validation_data=(X_test_reshaped, y_test), callbacks=[early_stopping])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152/1152 [==============================] - 4s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to make predictions on the testing dataset\n",
    "y_pred = lstm_model.predict(X_test_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new scaler for the output features\n",
    "output_scaler = StandardScaler()\n",
    "output_scaler.fit(target)\n",
    "# Invert the scaling of the predictions and actual values\n",
    "y_pred = output_scaler.inverse_transform(y_pred)\n",
    "y_test = output_scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the performance of the model using metrics like mean squared error, mean absolute error, and R-squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.1315369983738836e-06\n",
      "Mean Absolute Error: 0.0008963336806977938\n",
      "R-squared: 0.8851579454913193\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "lstm_model.save(\"lstm2_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "value_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
